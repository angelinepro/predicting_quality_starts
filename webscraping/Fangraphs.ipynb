{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Fangraphs Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes how to scrape historical baseball projection data from Fangraphs, to be used later to predict pitcher quality starts. I'll be scraping three years of projection data (2017, 2018, 2019) for each team, with each team-year of projection data on its own page. Each page of projection data has 2-3 tables with the statistics I want: \"Pitchers, Counting Stats\", \"Pitchers, Rates and Averages\", and \"Pitchers, Assorted Other\". To give an example, the Counting Stats table looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T20:30:33.652240Z",
     "start_time": "2020-06-30T20:30:33.533752Z"
    }
   },
   "source": [
    "![](img/counting_stats_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Page Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I’m going to use the requests library to send HTTP requests and retrieve the page source code. I’ll use BeautifulSoup to parse the HTML that comes back, along with re, the regular expressions library, to find and extract the data I care about. I’m also going to load pandas to put it all into dataframes after getting the data I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started by getting the list of URLS that I intended to scrape data from, taken from the links on this page (and similar pages for 2018 and 2019 projection data): https://blogs.fangraphs.com/category/2017-zips-projections/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_urls_2017 = [\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-baltimore-orioles',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-chicago-white-sox',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-houston-astros',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-boston-red-sox',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-cleveland-indians',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-los-angeles-angels',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-new-york-yankees',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-detroit-tigers',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-oakland-athletics',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-tampa-bay-rays',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-kansas-city-royals',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-seattle-mariners',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-toronto-blue-jays',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-minnesota-twins',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-texas-rangers',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-atlanta-braves',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-chicago-cubs',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-arizona-diamondbacks',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-miami-marlins',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-cincinnati-reds',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-colorado-rockies',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-new-york-mets',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-milwaukee-brewers',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-los-angeles-dodgers',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-philadelphia-phillies',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-pittsburgh-pirates',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-san-diego-padres',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-washington-nationals',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-st-louis-cardinals',\n",
    " 'http://www.fangraphs.com/blogs/2017-zips-projections-san-francisco-giants']\n",
    "\n",
    "list_urls_2018 = ['http://www.fangraphs.com/blogs/2018-zips-projections-baltimore-orioles',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-chicago-white-sox',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-houston-astros',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-boston-red-sox',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-cleveland-indians',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-los-angeles-angels',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-new-york-yankees',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-detroit-tigers',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-oakland-as',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-tampa-bay-rays',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-kansas-city-royals',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-seattle-mariners',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-toronto-blue-jays',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-minnesota-twins',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-texas-rangers',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-atlanta-braves',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-chicago-cubs',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-arizona-diamondbacks',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-miami-marlins',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-cincinnati-reds',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-colorado-rockies',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-new-york-mets',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-milwaukee-brewers',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-los-angeles-dodgers',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-philadelphia-phillies',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-pittsburgh-pirates',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-san-diego-padres',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-washington-nationals',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-st-louis-cardinals',\n",
    " 'http://www.fangraphs.com/blogs/2018-zips-projections-san-francisco-giants']\n",
    "\n",
    "list_urls_2019 = [\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-baltimore-orioles',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-chicago-white-sox',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projection-houston-astros',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-boston-red-sox',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-cleveland-indians',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-los-angeles-angels',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-new-york-yankees',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-detroit-tigers',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-oakland-athletics',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-tampa-bay-rays',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-kansas-city-royals',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-seattle-mariners',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-toronto-blue-jays',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-minnesota-twins',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-texas-rangers',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-atlanta-braves',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-chicago-cubs',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-arizona-diamondbacks',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-miami-marlins',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-cincinnati-reds',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-colorado-rockies',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-new-york-mets',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-milwaukee-brewers',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-los-angeles-dodgers',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-philadelphia-phillies',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-pittsburgh-pirates',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-san-diego-padres',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-washington-nationals',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-st-louis-cardinals',\n",
    " 'http://www.fangraphs.com/blogs/2019-zips-projections-san-francisco-giants']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each page, I want to extract the source. I wrote this function that appends the source for each page into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(urls):\n",
    "    response = []\n",
    "    for i in urls:\n",
    "        response.append(requests.get(i))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start with the 2017 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = get_data(list_urls_2017) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the source for all the 2017 ZiPS projections, I can write a function to parse them with BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(response_list):\n",
    "    soup = []\n",
    "    for i in response_list:\n",
    "        soup.append(BeautifulSoup(i.text, 'html5lib'))\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = make_soup(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This soups object now contains the parsed source code for 2017 projection data for each team. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Pitching Counts Table Data From Page Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a series for each of the columns in the table, to be combined back into a table later. I'm sure there is a more elegant solution for this, but this works for my purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_column(number, data, upper_limit, num_cols):\n",
    "    name = []\n",
    "    name_list = []\n",
    "    for i in range(0, upper_limit):\n",
    "        name.append(number + i*num_cols)\n",
    "    for i in name:\n",
    "        name_list.append(data[i])\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts the team name from the source, so it can be added to the resulting dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_name(team_data, upper_limit):\n",
    "    team_list = []\n",
    "    team_clean = re.findall('[\\s(A-z)]+[\\|]', team_data)[0].replace('|', '').strip()\n",
    "    for i in range(0, upper_limit):\n",
    "        team_list.append(team_clean)\n",
    "    return team_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses extract_column and team_name to generate the dataframes for each team's counting stats, for 2017. There's a lot in this function, and I want to highlight the .find() function, from BeautifulSoup. This is the function that identifies the table I want to extract data from in the source code, and takes values from those tables to create the series (using the extract_column function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pitching(soup_list, text_id, num_cols):\n",
    "    pitch_list = []\n",
    "    for j in soup_list:\n",
    "        data_crude = j.find(text = text_id).findNext().text.split(\"\\n\")\n",
    "        data_crude2 = []\n",
    "        for i in data_crude:\n",
    "            if i != '':\n",
    "                data_crude2.append(i)\n",
    "        data = data_crude2[num_cols:]\n",
    "        headers = data_crude2[:num_cols]\n",
    "        headers.insert(1, \"Team\")\n",
    "        team_data = j.find('title').text\n",
    "        upper_bound = int(len(data)/num_cols)\n",
    "        names = extract_column(0, data, upper_bound, num_cols)\n",
    "        team = team_name(team_data, upper_bound)\n",
    "        throws = extract_column(1, data, upper_bound, num_cols)\n",
    "        age = extract_column(2, data, upper_bound, num_cols)\n",
    "        games = extract_column(3, data, upper_bound, num_cols)\n",
    "        games_started = extract_column(4, data, upper_bound, num_cols)\n",
    "        innings_pitched = extract_column(5, data, upper_bound, num_cols)\n",
    "        strikeouts = extract_column(6, data, upper_bound, num_cols)\n",
    "        walks = extract_column(7, data, upper_bound, num_cols)\n",
    "        homeruns = extract_column(8, data, upper_bound, num_cols)\n",
    "        hits = extract_column(9, data, upper_bound, num_cols)\n",
    "        runs = extract_column(10, data, upper_bound, num_cols)\n",
    "        earned_runs = extract_column(11, data, upper_bound, num_cols)\n",
    "        pitch_data = pd.DataFrame(list(zip(names, \n",
    "                                           team,\n",
    "                                           throws,\n",
    "                                           age,\n",
    "                                           games,\n",
    "                                           games_started,\n",
    "                                           innings_pitched,\n",
    "                                           strikeouts,\n",
    "                                           walks,\n",
    "                                           homeruns,\n",
    "                                           hits,\n",
    "                                           runs,\n",
    "                                           earned_runs)),\n",
    "                                 columns = headers)\n",
    "        pitch_list.append(pitch_data)\n",
    "    pitching = pd.concat(pitch_list, ignore_index = True, axis = 0)\n",
    "    return pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to get all pitching counting stats for 2017, table has 12 columns\n",
    "pitch_data = extract_pitching(soups, \"Pitchers, Counting Stats\", 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Pitching Rates Table Data From Page Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is similar to the one above, accounting for different columns in the pitching rates table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pitching_rates(soup_list, text_id, num_cols):\n",
    "    pitch_list = []\n",
    "    for i in soup_list:\n",
    "        data_crude = i.find(text = text_id).findNext().text.split(\"\\n\")\n",
    "        data_crude2 = []\n",
    "        for i in data_crude:\n",
    "            if i != '':\n",
    "                data_crude2.append(i)\n",
    "        headers = data_crude2[:num_cols]\n",
    "        data = data_crude2[num_cols:]\n",
    "        upper_bound = int(len(data)/num_cols)\n",
    "        names = extract_column(0, data, upper_bound, num_cols)\n",
    "        IPs = extract_column(1, data, upper_bound, num_cols)\n",
    "        TBFs = extract_column(2, data, upper_bound, num_cols)\n",
    "        K_pcts = extract_column(3, data, upper_bound, num_cols)\n",
    "        BB_pcts = extract_column(4, data, upper_bound, num_cols)\n",
    "        BABIPs = extract_column(5, data, upper_bound, num_cols)\n",
    "        ERAs = extract_column(6, data, upper_bound, num_cols)\n",
    "        FIPs = extract_column(7, data, upper_bound, num_cols)\n",
    "        ERA_minus = extract_column(8, data, upper_bound, num_cols)\n",
    "        FIP_minus = extract_column(9, data, upper_bound, num_cols)\n",
    "        pitch_data = pd.DataFrame(list(zip(names, \n",
    "                                           IPs,\n",
    "                                           TBFs,\n",
    "                                           K_pcts,\n",
    "                                           BB_pcts,\n",
    "                                           BABIPs,\n",
    "                                           ERAs,\n",
    "                                           FIPs,\n",
    "                                           ERA_minus,\n",
    "                                           FIP_minus)),\n",
    "                                 columns = headers)\n",
    "        pitch_list.append(pitch_data)\n",
    "    pitching = pd.concat(pitch_list, ignore_index = True, axis = 0)\n",
    "    return pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to get all pitching rate stats for 2017, table has 10 columns\n",
    "pitch_rates_data = extract_pitching_rates(soups, \"Pitchers, Rates and Averages\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Pitching Other Table Data From Page Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pitching_other(soup_list, text_id, num_cols):\n",
    "    pitch_list = []\n",
    "    for i in soup_list:\n",
    "        data_crude = i.find(text = text_id).findNext().text.split(\"\\n\")\n",
    "        data_crude2 = []\n",
    "        for i in data_crude:\n",
    "            if i != '':\n",
    "                data_crude2.append(i)\n",
    "        headers = data_crude2[:num_cols]\n",
    "        data = data_crude2[num_cols:]\n",
    "        upper_bound = int(len(data)/num_cols)\n",
    "        names = extract_column(0, data, upper_bound, num_cols)\n",
    "        IPs = extract_column(1, data, upper_bound, num_cols)\n",
    "        K_9s = extract_column(2, data, upper_bound, num_cols)\n",
    "        BB_9s = extract_column(3, data, upper_bound, num_cols)\n",
    "        HR_9s = extract_column(4, data, upper_bound, num_cols)\n",
    "        ERA_plus = extract_column(5, data, upper_bound, num_cols)\n",
    "        zWARs = extract_column(6, data, upper_bound, num_cols)\n",
    "        competition = extract_column(7, data, upper_bound, num_cols)\n",
    "        pitch_data = pd.DataFrame(list(zip(names, \n",
    "                                           IPs,\n",
    "                                           K_9s,\n",
    "                                           BB_9s,\n",
    "                                           HR_9s,\n",
    "                                           ERA_plus,\n",
    "                                           zWARs,\n",
    "                                           competition)),\n",
    "                                 columns = headers)\n",
    "        pitch_list.append(pitch_data)\n",
    "    pitching = pd.concat(pitch_list, ignore_index = True, axis = 0)\n",
    "    return pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to get all other pitching stats for 2017, table has 8 columns\n",
    "pitch_other_data = extract_pitching_other(soups, \"Pitchers, Assorted Other\", 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Counting, Rate, and Other Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_rates_data.drop(columns = ['Player', 'IP'], inplace = True)\n",
    "pitch_other_data.drop(columns = ['Player', 'IP', 'No. 1 Comp'], inplace = True)\n",
    "#Start with counting and rates data\n",
    "partial = pd.concat([pitch_data, pitch_rates_data], axis = 1)\n",
    "#Add in other data\n",
    "full = pd.concat([partial, pitch_other_data], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the dataframe to make sure this is what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>T</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>IP</th>\n",
       "      <th>K</th>\n",
       "      <th>BB</th>\n",
       "      <th>HR</th>\n",
       "      <th>...</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>ERA</th>\n",
       "      <th>FIP</th>\n",
       "      <th>ERA-</th>\n",
       "      <th>FIP-</th>\n",
       "      <th>K/9</th>\n",
       "      <th>BB/9</th>\n",
       "      <th>HR/9</th>\n",
       "      <th>ERA+</th>\n",
       "      <th>zWAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kevin Gausman</td>\n",
       "      <td>Baltimore Orioles</td>\n",
       "      <td>R</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>176.0</td>\n",
       "      <td>162</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>.297</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.82</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>8.28</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.07</td>\n",
       "      <td>104</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dylan Bundy</td>\n",
       "      <td>Baltimore Orioles</td>\n",
       "      <td>R</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>109.3</td>\n",
       "      <td>108</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>.298</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.75</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>8.89</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.07</td>\n",
       "      <td>110</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Tillman</td>\n",
       "      <td>Baltimore Orioles</td>\n",
       "      <td>R</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>167.0</td>\n",
       "      <td>133</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>.287</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.30</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>7.17</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.13</td>\n",
       "      <td>95</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zach Britton</td>\n",
       "      <td>Baltimore Orioles</td>\n",
       "      <td>L</td>\n",
       "      <td>29</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>.276</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.64</td>\n",
       "      <td>52</td>\n",
       "      <td>61</td>\n",
       "      <td>10.27</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.70</td>\n",
       "      <td>181</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mychal Givens</td>\n",
       "      <td>Baltimore Orioles</td>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>79.3</td>\n",
       "      <td>101</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>.298</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.03</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>11.46</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>138</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brad Brach</td>\n",
       "      <td>Baltimore Orioles</td>\n",
       "      <td>R</td>\n",
       "      <td>31</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>.278</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.25</td>\n",
       "      <td>71</td>\n",
       "      <td>75</td>\n",
       "      <td>10.58</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.97</td>\n",
       "      <td>134</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Player               Team  T Age   G  GS     IP    K  BB  HR  ...  \\\n",
       "0  Kevin Gausman  Baltimore Orioles  R  26  31  31  176.0  162  55  21  ...   \n",
       "1    Dylan Bundy  Baltimore Orioles  R  24  19  19  109.3  108  36  13  ...   \n",
       "2  Chris Tillman  Baltimore Orioles  R  29  29  29  167.0  133  60  21  ...   \n",
       "3   Zach Britton  Baltimore Orioles  L  29  66   0   64.0   73  18   5  ...   \n",
       "4  Mychal Givens  Baltimore Orioles  R  27  63   0   79.3  101  31   7  ...   \n",
       "5     Brad Brach  Baltimore Orioles  R  31  63   0   74.0   87  29   8  ...   \n",
       "\n",
       "  BABIP   ERA   FIP ERA- FIP-    K/9  BB/9  HR/9 ERA+ zWAR  \n",
       "0  .297  3.94  3.82   92   88   8.28  2.81  1.07  104  2.8  \n",
       "1  .298  3.70  3.75   86   86   8.89  2.96  1.07  110  2.1  \n",
       "2  .287  4.31  4.30  100   99   7.17  3.23  1.13   95  1.9  \n",
       "3  .276  2.25  2.64   52   61  10.27  2.53  0.70  181  1.7  \n",
       "4  .298  2.95  3.03   69   70  11.46  3.52  0.79  138  1.4  \n",
       "5  .278  3.04  3.25   71   75  10.58  3.53  0.97  134  1.2  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check columns and preview dataframe\n",
    "full.columns\n",
    "full.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good! I'll save this as a csv file, so it can be easily loaded later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full.to_csv('projected_2017.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerunning to Scrape and Process 2018 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with the 2018 data is pretty straightforward, now that we've processed the data from 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = get_data(list_urls_2018) \n",
    "soups = make_soup(responses)\n",
    "pitch_data = extract_pitching(soups, \"Pitchers, Counting Stats\", 12)\n",
    "pitch_rates_data = extract_pitching_rates(soups, \"Pitchers, Rates and Averages\", 10)\n",
    "pitch_other_data = extract_pitching_other(soups, \"Pitchers, Assorted Other\", 8)\n",
    "pitch_rates_data.drop(columns = ['Player', 'IP'], inplace = True)\n",
    "pitch_other_data.drop(columns = ['Player', 'IP', 'No. 1 Comp'], inplace = True)\n",
    "partial = pd.concat([pitch_data, pitch_rates_data], axis = 1)\n",
    "full = pd.concat([partial, pitch_other_data], axis = 1)\n",
    "#full.to_csv('projected_2018.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerunning to Scrape and Process 2019 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019 is less straightforward. The tables are laid out differently, and one of the teams has one less column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = get_data(list_urls_2019) \n",
    "soups = make_soup(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get pitching counting stats. Many more columns present than in 2017/2018.\n",
    "def extract_pitching_2019(soup_list, text_id, num_cols):\n",
    "    pitch_list = []\n",
    "    for j in soup_list:\n",
    "        data_crude = j.find(text = text_id).findNext().text.split(\"\\n\")\n",
    "        data_crude2 = []\n",
    "        for i in data_crude:\n",
    "            if i != '':\n",
    "                data_crude2.append(i)\n",
    "        data = data_crude2[num_cols:]\n",
    "        headers = data_crude2[:num_cols]\n",
    "        headers.insert(1, \"Team\")\n",
    "        team_data = j.find('title').text\n",
    "        upper_bound = int(len(data)/num_cols)\n",
    "        names = extract_column(0, data, upper_bound, num_cols)\n",
    "        team = team_name(team_data, upper_bound)\n",
    "        throws = extract_column(1, data, upper_bound, num_cols)\n",
    "        age = extract_column(2, data, upper_bound, num_cols)\n",
    "        wins = extract_column(3, data, upper_bound, num_cols)\n",
    "        losses = extract_column(4, data, upper_bound, num_cols)\n",
    "        ERA = extract_column(5, data, upper_bound, num_cols)\n",
    "        games = extract_column(6, data, upper_bound, num_cols)\n",
    "        games_started = extract_column(7, data, upper_bound, num_cols)\n",
    "        innings_pitched = extract_column(8, data, upper_bound, num_cols)\n",
    "        hits = extract_column(9, data, upper_bound, num_cols)\n",
    "        earned_runs = extract_column(10, data, upper_bound, num_cols)\n",
    "        homeruns = extract_column(11, data, upper_bound, num_cols)\n",
    "        walks = extract_column(12, data, upper_bound, num_cols)\n",
    "        strikeouts = extract_column(13, data, upper_bound, num_cols)\n",
    "        pitch_data = pd.DataFrame(list(zip(names, \n",
    "                                           team,\n",
    "                                           throws,\n",
    "                                           age,\n",
    "                                           wins, \n",
    "                                           losses, \n",
    "                                           ERA, \n",
    "                                           games, \n",
    "                                           games_started, \n",
    "                                           innings_pitched,\n",
    "                                           hits, \n",
    "                                           earned_runs, \n",
    "                                           homeruns, \n",
    "                                           walks, \n",
    "                                           strikeouts)),\n",
    "                                 columns = headers)\n",
    "        pitch_list.append(pitch_data)\n",
    "    pitching = pd.concat(pitch_list, ignore_index = True, axis = 0)\n",
    "    return pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to get all pitching counting stats for 2019, table has 14 columns\n",
    "pitch_data = extract_pitching_2019(soups, 'Pitchers – Counting Stats', 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get pitching rates. Note this doesn't work for one team's data.\n",
    "def extract_pitching_rates_2019(soup_list, text_id, num_cols):\n",
    "    pitch_list = []\n",
    "    for j in soup_list:\n",
    "        data_crude = j.find(text = text_id).parent.parent.parent.text.split(\"\\n\")\n",
    "        data_crude2 = []\n",
    "        for i in data_crude:\n",
    "            if i != '':\n",
    "                data_crude2.append(i)\n",
    "        data = data_crude2[num_cols:]\n",
    "        headers = data_crude2[:num_cols]\n",
    "        upper_bound = int(len(data)/num_cols)\n",
    "        names = extract_column(0, data, upper_bound, num_cols)\n",
    "        IPs = extract_column(1, data, upper_bound, num_cols)\n",
    "        TBFs = extract_column(2, data, upper_bound, num_cols)\n",
    "        K_9s = extract_column(3, data, upper_bound, num_cols)\n",
    "        BB_9s = extract_column(4, data, upper_bound, num_cols)\n",
    "        HR_9s = extract_column(5, data, upper_bound, num_cols)\n",
    "        BABIPs = extract_column(6, data, upper_bound, num_cols)\n",
    "        ERA_plus = extract_column(5, data, upper_bound, num_cols)\n",
    "        ERA_minus = extract_column(8, data, upper_bound, num_cols)\n",
    "        FIPs = extract_column(9, data, upper_bound, num_cols)\n",
    "        WAR = extract_column(10, data, upper_bound, num_cols)\n",
    "        pitch_data = pd.DataFrame(list(zip(names, \n",
    "                                           IPs,\n",
    "                                           TBFs,\n",
    "                                           K_9s,\n",
    "                                           BB_9s,\n",
    "                                           HR_9s,\n",
    "                                           BABIPs,\n",
    "                                           ERA_plus,\n",
    "                                           ERA_minus,                                           \n",
    "                                           FIPs,                                        \n",
    "                                           WAR)),\n",
    "                                 columns = headers)\n",
    "        pitch_list.append(pitch_data)\n",
    "    pitching = pd.concat(pitch_list, ignore_index = True, axis = 0)\n",
    "    return pitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the teams has one fewer columns than the others, so I will remove it from the list and process it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_soup = soups[0:4] + soups[5:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can get all of the pitching rate stats (except for the one rogue team)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to get all (but one team's) pitching rate stats for 2019, table has 11 columns\n",
    "pitch_rates_data = extract_pitching_rates_2019(new_soup, 'TBF', 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is modified to account for the one team that has one less column than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get pitching rates. Note this is particular for one team's data. Doesn't\n",
    "#contain ERA_minus data.\n",
    "def extract_pitching_rates_2019_4(soup_list, text_id, num_cols):\n",
    "    pitch_list = []\n",
    "    for j in soup_list:\n",
    "        data_crude = j.find(text = text_id).parent.parent.parent.text.split(\"\\n\")\n",
    "        data_crude2 = []\n",
    "        for i in data_crude:\n",
    "            if i != '':\n",
    "                data_crude2.append(i)\n",
    "        data = data_crude2[num_cols:]\n",
    "        headers = data_crude2[:num_cols]\n",
    "        upper_bound = int(len(data)/num_cols)\n",
    "        names = extract_column(0, data, upper_bound, num_cols)\n",
    "        IPs = extract_column(1, data, upper_bound, num_cols)\n",
    "        TBFs = extract_column(2, data, upper_bound, num_cols)\n",
    "        K_9s = extract_column(3, data, upper_bound, num_cols)\n",
    "        BB_9s = extract_column(4, data, upper_bound, num_cols)\n",
    "        HR_9s = extract_column(5, data, upper_bound, num_cols)\n",
    "        BABIPs = extract_column(6, data, upper_bound, num_cols)\n",
    "        ERA_plus = extract_column(7, data, upper_bound, num_cols)\n",
    "        FIPs = extract_column(8, data, upper_bound, num_cols)\n",
    "        WAR = extract_column(9, data, upper_bound, num_cols)\n",
    "        pitch_data = pd.DataFrame(list(zip(names, \n",
    "                                           IPs,\n",
    "                                           TBFs,\n",
    "                                           K_9s,\n",
    "                                           BB_9s,\n",
    "                                           HR_9s,\n",
    "                                           BABIPs,\n",
    "                                           ERA_plus,                                     \n",
    "                                           FIPs,                                        \n",
    "                                           WAR)),\n",
    "                                 columns = headers)\n",
    "        pitch_list.append(pitch_data)\n",
    "    pitching = pd.concat(pitch_list, ignore_index = True, axis = 0)\n",
    "    return pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work with just the one team's data that has a different number of columns\n",
    "soups4 = [soups[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call function to get one team's pitching rate stats for 2019, table has 10 columns\n",
    "pitch_rates_data_4 = extract_pitching_rates_2019_4(soups4, 'TBF', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can splice all of the team data back together, remove redundant and unnecessary columns, and reorder as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splicing the one team's data back in\n",
    "pitch_rates_data_p1 = pitch_rates_data.iloc[0:175]\n",
    "pitch_rates_data_p3 = pitch_rates_data.iloc[175:]\n",
    "pitch_rates_combined = pd.concat([pitch_rates_data_p1, pitch_rates_data_4, pitch_rates_data_p3], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing redundant columns and No.1 Comp column.\n",
    "pitch_rates_combined.drop(columns = ['Player', 'No. 1 Comp'], inplace = True)\n",
    "full_2019 = pd.concat([pitch_data, pitch_rates_combined], axis = 1)\n",
    "#Reordering dataframe to match 2017-2018 column order\n",
    "projected_2019 = full_2019[['Player', 'Team', 'T', 'Age', 'G', 'GS', 'IP', 'SO', \n",
    "                            'BB', 'HR', 'H', 'ER', 'TBF', 'BABIP', 'ERA', 'FIP', \n",
    "                            'ERA-', 'K/9', 'BB/9', 'HR/9', 'ERA+', 'WAR', 'W', 'L']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print full 2018 pitching data to csv, \n",
    "# commented out so datafile is not overwritten each time code is run\n",
    "#projected_2019.to_csv('projected_2019.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of of this, we have three years of projection data for pitching. This can all be done in Beautiful Soup, because all of the data I need is already visible on the page once it is rendered. To get season data, I scrape regular season data from Baseball Reference that uses Javascript, which requires using Selenium (covered in the Baseball Reference Notebook in the repo). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.542px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
